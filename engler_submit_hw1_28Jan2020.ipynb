{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Copy of hw1-naive-bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonEngler/nearestNeighbor/blob/master/engler_submit_hw1_28Jan2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVc692cTWmeb",
        "colab_type": "text"
      },
      "source": [
        "You can do this homework online through [Google Colab](https://colab.research.google.com/). By linking Colab to Github, you can import this file to colab, and save your changes back to Github directly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kMl81pn0_3N",
        "colab_type": "text"
      },
      "source": [
        "# Homework 1: Naive Bayes Classifier\n",
        "\n",
        "In this homework you will implement the Naive Bayes Classsifier on a data set of votes in the U.S. House of Representatives, with the goal of predicting the party affiliation of each congressman. The input data $X$ is given by a $N$-by-$D$ matrix, where $N$ is the number of examples and $D=16$ is the number of input features. Each feature is binary (yes/no). The targets are given by a length-$N$ sequence of classes, $Y$, that are also binary. More information on the data set can be found at  https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JXBHBH70_3P",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "First, we need to download the data. The following code uses the urllib library to request data from a website. The pandas library is a powerful library for data analysis --- we use the read_csv method to automatically parse the comma seperated variable (csv) file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc-pnkGp0_3T",
        "colab_type": "code",
        "outputId": "9deef207-761c-436e-a6f1-a5c59f3abafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import pandas \n",
        "import urllib.request  \n",
        "import numpy   # Numerical python.\n",
        "import math\n",
        "import collections\n",
        "\n",
        "# Download the data.\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\"\n",
        "response = urllib.request.urlopen(url)\n",
        "\n",
        "# Interpret text data into pandas data frame. Interpret 'abstain' votes as 'no'.\n",
        "dataset  = pandas.read_csv(response, header=None, true_values=['y'], false_values=['n','?'])\n",
        "\n",
        "# Set the column names.\n",
        "names = ['label'] + [f'vote_{i}' for i in range(16)]\n",
        "dataset.columns = names\n",
        "\n",
        "# Tells pandas that this is a categorical feature.\n",
        "dataset['label'] = pandas.Categorical(dataset['label'])\n",
        "\n",
        "print(\"Dataset shape: \", dataset.shape)\n",
        "dataset.head() # Prints first 5 examples from the data set."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape:  (435, 17)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>vote_0</th>\n",
              "      <th>vote_1</th>\n",
              "      <th>vote_2</th>\n",
              "      <th>vote_3</th>\n",
              "      <th>vote_4</th>\n",
              "      <th>vote_5</th>\n",
              "      <th>vote_6</th>\n",
              "      <th>vote_7</th>\n",
              "      <th>vote_8</th>\n",
              "      <th>vote_9</th>\n",
              "      <th>vote_10</th>\n",
              "      <th>vote_11</th>\n",
              "      <th>vote_12</th>\n",
              "      <th>vote_13</th>\n",
              "      <th>vote_14</th>\n",
              "      <th>vote_15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>republican</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>republican</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>democrat</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>democrat</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>democrat</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label  vote_0  vote_1  vote_2  ...  vote_12  vote_13  vote_14  vote_15\n",
              "0  republican   False    True   False  ...     True     True    False     True\n",
              "1  republican   False    True   False  ...     True     True    False    False\n",
              "2    democrat   False    True    True  ...     True     True    False    False\n",
              "3    democrat   False    True    True  ...     True    False    False     True\n",
              "4    democrat    True    True    True  ...     True     True     True     True\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks-snVmYvSW2",
        "colab_type": "text"
      },
      "source": [
        "Numpy is a powerful library for mathematical operations on vectors and matrices. Here we convert the pandas data into a 2-dimensional numpy array (a matrix). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJjff58Uu4kw",
        "colab_type": "code",
        "outputId": "d80c3981-c10f-4216-bbbb-587bdf46bd8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = numpy.array(dataset.iloc[:,1:]) # Convert input features into Numpy array.\n",
        "Y = dataset['label'].cat.codes # Converts string labels to binary values.\n",
        "\n",
        "# Split data into train and test set. Use the first 335 examples for training.\n",
        "num_train = 335\n",
        "Xtrain = X[0:num_train, :].astype('float32')\n",
        "Ytrain = Y[0:num_train].astype('f')\n",
        "Xtest  = X[num_train:,:].astype('f')\n",
        "Ytest  = Y[num_train:].astype('f')\n",
        "\n",
        "print(Xtrain.shape, Xtest.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(335, 16) (100, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZGCc_KHu6yR",
        "colab_type": "text"
      },
      "source": [
        "You are asked to implement the following functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-UW7SoRzog",
        "colab_type": "code",
        "outputId": "02c7d093-0a44-4dfd-93fc-7cfece9e4ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def get_distance(q, X):\n",
        "  #Distance between query q and every point in data matrix X\n",
        "  np = numpy\n",
        "  N, D = X.shape\n",
        "  assert(len(q) == D)\n",
        "  rval = np.zeros((N,))\n",
        "  for i in range(N):\n",
        "    distance = np.sqrt(np.sum((q - X[i, :])**2))\n",
        "    rval[i] = distance\n",
        "  return rval\n",
        "\n",
        "def get_distance_vectorized(q,X):\n",
        "  np = numpy\n",
        "  return np.sqrt(np.sum((q - X)**2, axis=1)) #broadcasting vector into matrix\n",
        "\n",
        "get_distance(Xtest[0,:], Xtrain[:10,:])\n",
        "\n",
        "get_distance_vectorized(Xtest[0,:], Xtrain[:10,:])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.7320508, 1.7320508, 2.236068 , 2.828427 , 2.828427 , 2.828427 ,\n",
              "       2.6457512, 2.236068 , 2.       , 3.7416575], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUMRDUDnV563",
        "colab_type": "code",
        "outputId": "bb6ed244-e23e-46cf-d3e7-79e8f3db8db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def classify(q, Xtrain, Ytrain):\n",
        "  np = numpy\n",
        "  distances = get_distance_vectorized(q, Xtrain)\n",
        "  min_idx = np.argmin(distances)\n",
        "  #This is the minimum value: distances[min_idx]\n",
        "  return Ytrain[min_idx]\n",
        "\n",
        "np = numpy\n",
        "preds = np.zeros((100,))\n",
        "for i,q in enumerate(Xtest):\n",
        "  preds[i] = classify(q, Xtrain, Ytrain)\n",
        "print(\"Accuracy is:%0.2f\" % (np.sum(preds == Ytest)/len(Ytest)))\n",
        " "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is:0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTGyr4NKaKCT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCpOIkEA0_3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Reference: (https://hackernoon.com/implementation-of-gaussian-naive-bayes-in-python-from-scratch-c4ea64e3944d)\n",
        "def generative_model(Xtrain, Ytrain):\n",
        "    ''' i\n",
        "    Implements a generative algorithm on binary data.\n",
        "    Inputs\n",
        "        Xtrain: NxD matrix of features.\n",
        "        Ytrain: N vector of class labels\n",
        "    \n",
        "    Returns\n",
        "        p_label: Length 2 vector of class probabilities.\n",
        "        p_votes: 2xD Matrix where entry i,j is p(x_j|v=i).\n",
        "    ''' \n",
        "    # WRITE ME\n",
        "    p_label = np.ones(2)\n",
        "    y_dict = collections.Counter(Ytrain)\n",
        "    for i in range(0,2):\n",
        "      p_label[i] = y_dict[i]/Ytrain.shape[0]\n",
        "       \n",
        "    #p_label = [0.5, 0.5]   \n",
        "    #Probability of voting using Xtrain votes\n",
        "    D = Xtrain.shape[1]\n",
        "    N = Xtrain.shape[0]\n",
        "    p_votes = np.ones((2,D))\n",
        "    total_R = np.ones(D)\n",
        "    total_D = np.ones(D)\n",
        "    \n",
        "    #Count number of Republicans\n",
        "    num_republicans = 0\n",
        "    num_democrats = 0\n",
        "    for i in range(0,N):\n",
        "        if Ytrain[i] == 1:\n",
        "            num_republicans = num_republicans + 1\n",
        "        else:\n",
        "            num_democrats = num_democrats + 1\n",
        "    print(\"Republicans: \", num_republicans)\n",
        "    print(\"Democrats: \", num_democrats)\n",
        "    \n",
        "    #Split republican and democrat votes\n",
        "    D_prob = np.ones((num_democrats,D))\n",
        "    R_prob = np.ones((num_republicans,D))\n",
        "     \n",
        "    #If republican\n",
        "    for i in range(0, num_republicans):\n",
        "        #if Republican\n",
        "        if Ytrain[i] == 1:\n",
        "            R_prob[i][:] = Xtrain[i][:]\n",
        "    print(\"R_prob\", R_prob)\n",
        "    #democrat\n",
        "    for i in range(0, num_democrats):\n",
        "        if Ytrain[i] == 0:\n",
        "            D_prob[i][:] = Xtrain[i][:]\n",
        "    print(\"D_prob\", D_prob)        \n",
        "    for i in range(0, D):\n",
        "        total_D[i] = sum(D_prob[:][i])\n",
        "        p_votes[0][i] = (total_D[i]/Xtrain.shape[1])*p_label[0]\n",
        "    print(\"TOTAL_D:\", total_D)\n",
        "    for i in range(0, D):\n",
        "        total_R[i] = sum(R_prob[:][i])\n",
        "        p_votes[1][i] = (total_R[i]/Xtrain.shape[1])*p_label[1]\n",
        "    \n",
        "    print(\"TOTAL_R\", total_R)\n",
        "    #Calculate \n",
        "    print(\"Labels: \", p_label)\n",
        "    print(\"Votes: \", p_votes)\n",
        "    \n",
        "     #Calculate Log-Likelyhood\n",
        "    Loglike = 0\n",
        "    for i in range(0,p_votes.shape[0]):\n",
        "        for j in range(0,p_votes.shape[1]):\n",
        "            Loglike = Loglike + np.log((p_label[i])) + np.log((p_votes[i][j]))*np.log((p_label[i]))\n",
        "        \n",
        "    print(\"Log Sum:\", Loglike)\n",
        "    \n",
        "    return p_label, p_votes\n",
        "  \n",
        "def discriminative_model(p_label, p_votes, Xtest):\n",
        "    '''\n",
        "    Implements Naive Bayes Classification.\n",
        "    Inputs\n",
        "      p_label, p_votes: From generative_model.\n",
        "      Xtest: NxD matrix of binary features.\n",
        "    \n",
        "    Outputs \n",
        "      pred_prob: Probability of label=1 under model.\n",
        "    '''\n",
        "    # WRITE ME\n",
        "    N, D = Xtest.shape\n",
        "    pfc = np.ones(2)\n",
        "    pcf = np.ones(2)\n",
        "\n",
        "    for i in range(0, 2):\n",
        "        product = 1\n",
        "        for j in range(0, D):\n",
        "           # if(Xtest.shape[0] == 1):\n",
        "           #     product = p_votes[i][j] * Xtest[0][j]\n",
        "           # else:\n",
        "           product = p_votes[i][j] * Xtest[i][j]\n",
        "        pfc[i] = product\n",
        "    \n",
        "    total_prob = 0\n",
        "    for i in range(0, 2):\n",
        "        total_prob = total_prob + (pfc[i] * p_label[i])\n",
        "    #print(\"Total Prob:\", total_prob)\n",
        "    for i in range(0, 2):\n",
        "        pcf[i] = (pfc[i] * p_label[i])/total_prob\n",
        "  #  print(\"PCF:\", pcf)\n",
        "    pred_prob = pcf[1]\n",
        "    return pred_prob\n",
        "\n",
        "def accuracy(y_true, y_predicted):\n",
        "    ''' Calculates the fraction of con\\rrect predictions.\n",
        "    '''\n",
        "    #assert(len(y_true) == len(y_predicted))\n",
        "    # WRITE ME\n",
        "    count = 0\n",
        "    for i in range(0,len(y_true)):\n",
        "        if y_predicted == y_true[i]:\n",
        "            count = count + 1\n",
        "        \n",
        "    fraction = 1 - count/len(y_true)\n",
        "    print(\"Total Accuracy: \", fraction)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG3FApKMaPxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huiM_v_7AQc1",
        "colab_type": "code",
        "outputId": "882320a1-9c82-4558-ec00-a2c583dd03a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Make sure to print these for submission.\n",
        "p_label, p_votes = generative_model(Xtrain, Ytrain)\n",
        "print('Label priors:', p_label)\n",
        "print('Conditional vote probabilities:', p_votes)\n",
        "\n",
        "pred_prob = discriminative_model(p_label, p_votes, Xtest)\n",
        "print('Predictions:', pred_prob)\n",
        "\n",
        "\n",
        "#The log probability of the test set is calculated as:\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Republicans:  127\n",
            "Democrats:  208\n",
            "R_prob [[0. 1. 0. ... 1. 0. 1.]\n",
            " [0. 1. 0. ... 1. 0. 0.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 0. 1.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n",
            "D_prob [[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [0. 1. 1. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n",
            "TOTAL_D: [16. 16.  7.  6. 10.  8.  7. 16. 16.  6. 16. 16.  6.  9. 16. 16.]\n",
            "TOTAL_R [ 9.  7. 16. 16. 16. 16. 16.  7.  8. 16.  5.  7. 16. 16.  5.  7.]\n",
            "Labels:  [0.62089552 0.37910448]\n",
            "Votes:  [[0.62089552 0.62089552 0.27164179 0.23283582 0.3880597  0.31044776\n",
            "  0.27164179 0.62089552 0.62089552 0.23283582 0.62089552 0.62089552\n",
            "  0.23283582 0.34925373 0.62089552 0.62089552]\n",
            " [0.21324627 0.16585821 0.37910448 0.37910448 0.37910448 0.37910448\n",
            "  0.37910448 0.16585821 0.18955224 0.37910448 0.11847015 0.16585821\n",
            "  0.37910448 0.37910448 0.11847015 0.16585821]]\n",
            "Log Sum: 5.255315287948211\n",
            "Label priors: [0.62089552 0.37910448]\n",
            "Conditional vote probabilities: [[0.62089552 0.62089552 0.27164179 0.23283582 0.3880597  0.31044776\n",
            "  0.27164179 0.62089552 0.62089552 0.23283582 0.62089552 0.62089552\n",
            "  0.23283582 0.34925373 0.62089552 0.62089552]\n",
            " [0.21324627 0.16585821 0.37910448 0.37910448 0.37910448 0.37910448\n",
            "  0.37910448 0.16585821 0.18955224 0.37910448 0.11847015 0.16585821\n",
            "  0.37910448 0.37910448 0.11847015 0.16585821]]\n",
            "Predictions: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re2cC82D0_3e",
        "colab_type": "text"
      },
      "source": [
        "## To turn in:\n",
        "1) Implement the Naive Bayes Classifier using the starter code above. Make sure to print out the parameters of the generative model and the predictions on the test points.\n",
        "\n",
        "**See code above.**\n",
        "\n",
        "Republicans:  127\n",
        "Democrats:  208\n",
        "R_prob [[0. 1. 0. ... 1. 0. 1.]\n",
        " [0. 1. 0. ... 1. 0. 0.]\n",
        " [1. 1. 1. ... 1. 1. 1.]\n",
        " ...\n",
        " [1. 1. 1. ... 1. 1. 1.]\n",
        " [0. 0. 0. ... 1. 0. 1.]\n",
        " [0. 0. 0. ... 1. 0. 0.]]\n",
        "D_prob [[1. 1. 1. ... 1. 1. 1.]\n",
        " [1. 1. 1. ... 1. 1. 1.]\n",
        " [0. 1. 1. ... 1. 0. 0.]\n",
        " ...\n",
        " [0. 0. 1. ... 0. 0. 1.]\n",
        " [1. 1. 1. ... 1. 1. 1.]\n",
        " [1. 1. 1. ... 1. 1. 1.]]\n",
        "TOTAL_D: [16. 16.  7.  6. 10.  8.  7. 16. 16.  6. 16. 16.  6.  9. 16. 16.]\n",
        "TOTAL_R [ 9.  7. 16. 16. 16. 16. 16.  7.  8. 16.  5.  7. 16. 16.  5.  7.]\n",
        "Labels:  [0.62089552 0.37910448]\n",
        "Votes:  [[0.62089552 0.62089552 0.27164179 0.23283582 0.3880597  0.31044776\n",
        "  0.27164179 0.62089552 0.62089552 0.23283582 0.62089552 0.62089552\n",
        "  0.23283582 0.34925373 0.62089552 0.62089552]\n",
        " [0.21324627 0.16585821 0.37910448 0.37910448 0.37910448 0.37910448\n",
        "  0.37910448 0.16585821 0.18955224 0.37910448 0.11847015 0.16585821\n",
        "  0.37910448 0.37910448 0.11847015 0.16585821]]\n",
        "Label priors: [0.62089552 0.37910448]\n",
        "Conditional vote probabilities: [[0.62089552 0.62089552 0.27164179 0.23283582 0.3880597  0.31044776\n",
        "  0.27164179 0.62089552 0.62089552 0.23283582 0.62089552 0.62089552\n",
        "  0.23283582 0.34925373 0.62089552 0.62089552]\n",
        " [0.21324627 0.16585821 0.37910448 0.37910448 0.37910448 0.37910448\n",
        "  0.37910448 0.16585821 0.18955224 0.37910448 0.11847015 0.16585821\n",
        "  0.37910448 0.37910448 0.11847015 0.16585821]]\n",
        "Predictions: 1.0\n",
        "\n",
        "\n",
        "2) Compute the log probability of the test set --- this is a single scalar value.\n",
        "\n",
        "Log Probability: 5.255315287948211\n",
        "\n",
        "3) Compare the NB classifier to a model in which we predict a 50-50 chance for each vote, in terms of accuracy and the log probability. Which model is better and why? Describe two situations in which the Naive Bayes Classifier will fail. \n",
        "\n",
        "\n",
        "**The log probability is better as it allows you to find the maximum log probability. The 50-50 chance for each vote does not predict well using the training data. ** \n",
        "\n",
        "** A Naive Bayes classifyer will fail if the only seperation between the two classes is the covariance. Also, it due to the conditional independance if you have no occurances of a catagory in your sample it can drop your probability estimate to zero      **\n",
        "\n",
        "**References**\n",
        "**https://www.youtube.com/watch?v=feBKiAdhYkc**\n",
        "**https://www.researchgate.net/post/What_are_the_disadvantages_of_Naive_Bayes**\n",
        "\n",
        "\n"
      ]
    }
  ]
}